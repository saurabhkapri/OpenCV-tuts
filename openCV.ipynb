{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 1152, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=cv2.imread(r'C:\\Users\\kapri\\Pictures\\bus.png')\n",
    "cv2.imshow('hs bus',input)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('hehe.png',input)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting to greyscale\n",
    "* coz they are less data in same details.\n",
    "* there are 2 ways of doing this-\n",
    "* cv2.COLOR_BGR2GRAY/writing 0 after your input image name is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image=cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray',gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image2=cv2.imread(r'C:\\Users\\kapri\\Pictures\\bus.png',0)\n",
    "cv2.imshow('a',gray_image2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 255, 255, (648, 1152, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,G,R=input[0,0]\n",
    "B,G,R,input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another useful colour space HSV\n",
    "* it is used in colour filtering\n",
    "* H: 0-179\n",
    "* S: 0-255\n",
    "* V: 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=cv2.imread(r'C:\\Users\\kapri\\Pictures\\s.png')\n",
    "hsv_image=cv2.cvtColor(input,cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('HSV imgae',hsv_image)                    #terrible image will get coz imshow shows BGR or RGB images and we are \n",
    "cv2.imshow('Hue channel',hsv_image[:,:,0])           #using hsv image\n",
    "cv2.imshow('Saturation channel',hsv_image[:,:,1])\n",
    "cv2.imshow('Value channel',hsv_image[:,:,2])\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individual channel in RGB image\n",
    "* cv2.split(loaded_image)-------->splits image in each image index\n",
    "* cv2.merge([array_of_diiffrent_chanells])------------------->combines image into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 375)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Pictures\\s.png')\n",
    "B,G,R=cv2.split(image)\n",
    "\n",
    "print(B.shape)\n",
    "\n",
    "cv2.imshow('RED',R)                 #we will see grayscale colour coz only one channel is shown\n",
    "cv2.imshow('GREEN',G)\n",
    "cv2.imshow('BLUE',B)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#creating remake image\n",
    "merged=cv2.merge([B,G,R])\n",
    "cv2.imshow('Merged',merged)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "#amplifying blue colour\n",
    "merged2=cv2.merge([B+100,G,R])\n",
    "cv2.imshow('MERGED with BLUE amplified',merged2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seeing all diffrent colours \n",
    "* coz above we only got the grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Pictures\\s.png')\n",
    "B,G,R=cv2.split(image)\n",
    "\n",
    "#creating matrix of zeros\n",
    "#with dimension of image h*w\n",
    "\n",
    "zeros=np.zeros(image.shape[:2],dtype='uint8')\n",
    "\n",
    "cv2.imshow('ReD',cv2.merge([zeros,zeros,R]))\n",
    "cv2.imshow('Green',cv2.merge([zeros,G,zeros]))\n",
    "cv2.imshow('Blue',cv2.merge([B,zeros,zeros]))\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# translation\n",
    "* this is a affine translation which shifts the position of the image\n",
    "* we us cv2.WarpAffine function to implement these translaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Pictures\\s.png')\n",
    "\n",
    "#store height and width of the image\n",
    "height,width=image.shape[:2]\n",
    "\n",
    "quater_height,quater_width=height/4,width/4\n",
    "\n",
    "\n",
    "#     /1 0 Tx /\n",
    "# T= /0 1 Ty /\n",
    "\n",
    "# T is our translation matrix\n",
    "T=np.float32([[1,0,quater_width],[0,1,quater_height]])\n",
    "\n",
    "#we use WrapAffine to transform image using matrix T\n",
    "\n",
    "img_translation=cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow('translation',img_translation)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  , 93.75],\n",
       "       [ 0.  ,  1.  , 52.  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation\n",
    "* cv2.getRotationMatrix2D(rotation_center_x,rotation_center_y,angle_of_rotation,scaling_factor)\n",
    "* rotates in anticlockwise direction\n",
    "* rotates along center in the anticlockwise direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:/Users/kapri/Pictures/arduino.png')\n",
    "\n",
    "#store height and width of an image\n",
    "height,width=image.shape[:2]\n",
    "\n",
    "rotation_matrix=cv2.getRotationMatrix2D((width/2,height/2),90,1)\n",
    "rotation_matrix2=cv2.getRotationMatrix2D((width/2,height/2),-90,1)\n",
    "\n",
    "\n",
    "img_rotation=cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "img_rotation2=cv2.warpAffine(image,rotation_matrix2,(width,height))\n",
    "\n",
    "\n",
    "cv2.imshow('rotated_image',img_rotation)\n",
    "cv2.imshow('rotated_image2',img_rotation2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the image\n",
    "\n",
    "* interpolation-methord of creating new datapoints within range of discrete set of known data points\n",
    "*  0_0\n",
    "*  0_0\n",
    "* cv2.INTER_AREA      -Good for shrinking or down sampling\n",
    "* cv2.INTER_NEAREST   -Fastest\n",
    "* cv2.INTER_LINEAR    -Good for Zooming up sampling(default)\n",
    "* cv2.INTER_CUBIC     -better\n",
    "* cv2.INTER_LANCZOS4  -best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# loading image\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\coffee.jpg')\n",
    "\n",
    "# making image 3/4 of the original\n",
    "image_scaled=cv2.resize(image,None,fx=0.75,fy=0.75)\n",
    "cv2.imshow('Scaling-Linear Interpolation',image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Doubling the size of the image\n",
    "img_scaled=cv2.resize(image,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('scaling-Cubic INTERPOLATION',img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "#lets skew the resizing by giving dimensions\n",
    "img_scaled=cv2.resize(image,(900,400),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling-Skewed Size',img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image pyramiding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\coffee.jpg')\n",
    "\n",
    "smaller=cv2.pyrDown(image)\n",
    "larger=cv2.pyrUp(smaller)        #here we will lose quality of the image coz we are upscaling a smaller image\n",
    "\n",
    "cv2.imshow('original',image)\n",
    "\n",
    "cv2.imshow('smaller',smaller)\n",
    "cv2.imshow('larger',larger)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "#for getting smaller and smaller images we can run a for loop and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cropping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\coffee.jpg')\n",
    "height,width=image.shape[:2]\n",
    "\n",
    "#we use numpy for doing so\n",
    "start_row,start_col=int(height*.25),int(width*.25)\n",
    "end_row,end_col=int(height*.75),int(width*.75)\n",
    "\n",
    "cropped=image[start_row:end_row,start_col:end_col]\n",
    "\n",
    "cv2.imshow('original image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Cropped image',cropped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arthematic operations\n",
    "these are simple operations that allows us to directly add or subtract color intensity.\n",
    "\n",
    "Calculates the per-element operation of two arrays.the overall effect is increasing or decreasing brightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\coffee.jpg')\n",
    "\n",
    "# create a matrix of ones and multiply it by factor\n",
    "# this gives a matrix with same dimensions as of image and all value equal to factor\n",
    "\n",
    "M=np.ones(image.shape,dtype='uint8')*75\n",
    "\n",
    "# we use this to add this matrix M,to our image\n",
    "# Notice increase in brightness\n",
    "added=cv2.add(image,M)\n",
    "cv2.imshow('added',added)\n",
    "\n",
    "#likewise we can also subtract\n",
    "#notice the decrease in brightness\n",
    "subtracted=cv2.subtract(image,M)\n",
    "cv2.imshow('subtracted',subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bitwise operation and masking\n",
    "to demonstrate this operations lets create some simple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#only 2 dimensions here means the image is grayscaled\n",
    "#if coloured we would have usen\n",
    "#rectangle=np.zeros((300,300,3),np.uint8)\n",
    "\n",
    "# making a square\n",
    "square=np.zeros((300,300),np.uint8)\n",
    "cv2.rectangle(square,(50,50),(250,250),255,-2)\n",
    "cv2.imshow('square',square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#making an ellipse\n",
    "ellipse=np.zeros((300,300),np.uint8)\n",
    "cv2.ellipse(ellipse,(150,150),(150,150),30,0,180,255,-1)\n",
    "cv2.imshow('ellipse',ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experementation with bitwise operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convlution and blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\elephant.jpg')\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#creating a 3x3 kernal\n",
    "kernel_3x3=np.ones((3,3),np.float32)/9\n",
    "\n",
    "#we use cv2.filter2D to conovle kernel with the image\n",
    "blurred=cv2.filter2D(image,-1,kernel_3x3)\n",
    "cv2.imshow('3x3 kernel blurring',blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#creating a 7x7 kernel\n",
    "kernel_7x7=np.ones((7,7),np.float32)/49\n",
    "\n",
    "blurred2=cv2.filter2D(image,-1,kernel_7x7)\n",
    "cv2.imshow('7x7 kernel blurring',blurred2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  other types of blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sharpening of an image\n",
    "* by altering our kernel we can implement sharpening,which emphasises on edges of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\input.jpg')\n",
    "cv2.imshow('original',image)\n",
    "\n",
    "#create our sharpening kernel,we dont normalize since\n",
    "#all the values sum upto one\n",
    "\n",
    "kernel_sharpening=np.array([[-2,-2,-2],\n",
    "                           [-2,17,-2],\n",
    "                           [-2,-2,-2]])\n",
    "\n",
    "#applying diffrent kernels to the input image\n",
    "\n",
    "sharpened=cv2.filter2D(image,-1,kernel_sharpening)\n",
    "\n",
    "cv2.imshow('image sharpening',sharpened)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thresholding\n",
    "* converting img to binary\n",
    "* THRESHOLD TYPES-\n",
    "* cv2.THRESH_BINARY-Most Common\n",
    "* cv2.THRESH_BINARY_INV-Most Common\n",
    "* cv2.THRESH_TRUNC\n",
    "* cv2.THRESH_TOZERO\n",
    "* CV2.THRESH_TOZERO_INV\n",
    "* __________________________________\n",
    "* note- image must be in grayscale before thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\elephant.jpg')\n",
    "cv2.imshow('orig',img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray',gray)\n",
    "\n",
    "ret,TB=cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('binary',TB)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DILATION, EROSION, OPENING, CLOSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\opencv.png',0)\n",
    "\n",
    "cv2.imshow('orig',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#lets define our kernel size\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "\n",
    "#erosion\n",
    "erosion=cv2.erode(image,kernel,iterations=1)\n",
    "cv2.imshow('eroded_img',erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#\n",
    "dilation=cv2.dilate(image,kernel,iterations=1)\n",
    "cv2.imshow('dilated_image',dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#opening-good for removing noise\n",
    "opening=cv2.morphologyEx(image,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow('opening',opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#closing good for removing noise\n",
    "closing=cv2.morphologyEx(image,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow('closing',closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edge detection and image gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\input.jpg',0)\n",
    "height, width=image.shape\n",
    "\n",
    "#extract Sobel Edges\n",
    "sobel_x=cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5)\n",
    "sobel_y=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5)\n",
    "\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('sobel_X',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('sobel_Y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR=cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel_or',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian=cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow('laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "#then we need to provide 2 values:threshold1 and threshold2,any gradient value larger tha T2 is edge\n",
    "#any value less than T1 is not an edge.\n",
    "#values b/w T1 and T2 are classified as edge on basis of how thiet intensities are connected\n",
    "#in this case any gradient value less than 60 are non-edge and values above 120 are edges\n",
    "\n",
    "#canny uses  gradient values as threshold\n",
    "canny=cv2.Canny(image,50,120)\n",
    "cv2.imshow('Canny',canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GETTING Prespective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\scan.jpg')\n",
    "cv2.imshow('original',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#points of the image\n",
    "points_A=np.float32([[327,14],[700,215],[80,621],[530,782]])\n",
    "\n",
    "#coordinates of 4 cornors of desired output\n",
    "#we use ratio of an A4 sheet 1:1.41\n",
    "points_B=np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "\n",
    "#use the 2 sets of 4 pionts to compute\n",
    "#the prespective tranformation matrix,M\n",
    "M=cv2.getPerspectiveTransform(points_A,points_B)\n",
    "\n",
    "wraped=cv2.warpPerspective(image,M,(420,594))\n",
    "\n",
    "cv2.imshow('wraped_prespective',wraped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## affine transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini project 1-Live sketch using webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#sketch generating function\n",
    "def sketch(image):\n",
    "    #converting image to greyscale\n",
    "    img_gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #cleaning with gaussian blur\n",
    "    img_gray_blur=cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    \n",
    "    canny_edges=cv2.Canny(img_gray_blur,20,80)\n",
    "    \n",
    "    #doing invert binarisation\n",
    "    ret,mask=cv2.threshold(canny_edges,70,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def gray(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def canny(image):\n",
    "    return cv2.Canny(image,10,70)\n",
    "\n",
    "def blur(image):\n",
    "    return cv2.GaussianBlur(image,(5,5),0)\n",
    "\n",
    "def more_red(image):\n",
    "    B,G,R=cv2.split(image)\n",
    "    merged=cv2.merge([B*0,G*0,R])\n",
    "    return merged\n",
    "\n",
    "def more_blue(image):\n",
    "    B,G,R=cv2.split(image)\n",
    "    merged2=cv2.merge([B,G*0,R*0])\n",
    "    return merged2\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "#cap.set(3,640)           #width feature\n",
    "#cap.set(4,480)           #height feature\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('original',frame)\n",
    "    cv2.imshow('gray',gray(frame))\n",
    "    cv2.imshow('Blur',blur(frame))\n",
    "    #cv2.imshow('canny',canny(frame))\n",
    "    cv2.imshow('sketch',sketch(frame))\n",
    "    cv2.imshow('red',more_red(frame))\n",
    "    #cv2.imshow('blue',more_blue(frame))\n",
    "\n",
    "    if cv2.waitKey(1)==13:                       #13 is the key for enter\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def sketch(image):\n",
    "    #converting image to greyscale\n",
    "    img_gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #cleaning with gaussian blur\n",
    "    img_gray_blur=cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    \n",
    "    canny_edges=cv2.Canny(img_gray_blur,20,80)\n",
    "    \n",
    "    #doing invert binarisation\n",
    "    ret,mask=cv2.threshold(canny_edges,70,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "img=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\elephant.jpg')\n",
    "cv2.imshow('orig',img)\n",
    "\n",
    "cv2.imshow('sketch',sketch(img))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of contors found= 8\n",
      "[array([[[368, 157]],\n",
      "\n",
      "       [[486, 157]],\n",
      "\n",
      "       [[487, 158]],\n",
      "\n",
      "       [[492, 158]],\n",
      "\n",
      "       [[493, 159]],\n",
      "\n",
      "       [[492, 160]],\n",
      "\n",
      "       [[492, 295]],\n",
      "\n",
      "       [[493, 296]],\n",
      "\n",
      "       [[493, 298]],\n",
      "\n",
      "       [[492, 299]],\n",
      "\n",
      "       [[492, 300]],\n",
      "\n",
      "       [[493, 301]],\n",
      "\n",
      "       [[491, 303]],\n",
      "\n",
      "       [[488, 303]],\n",
      "\n",
      "       [[487, 302]],\n",
      "\n",
      "       [[368, 302]],\n",
      "\n",
      "       [[367, 301]],\n",
      "\n",
      "       [[367, 297]],\n",
      "\n",
      "       [[366, 296]],\n",
      "\n",
      "       [[366, 159]]], dtype=int32), array([[[368, 157]],\n",
      "\n",
      "       [[366, 159]],\n",
      "\n",
      "       [[366, 296]],\n",
      "\n",
      "       [[367, 297]],\n",
      "\n",
      "       [[367, 302]],\n",
      "\n",
      "       [[487, 302]],\n",
      "\n",
      "       [[488, 303]],\n",
      "\n",
      "       [[491, 303]],\n",
      "\n",
      "       [[493, 301]],\n",
      "\n",
      "       [[492, 300]],\n",
      "\n",
      "       [[492, 299]],\n",
      "\n",
      "       [[493, 298]],\n",
      "\n",
      "       [[493, 296]],\n",
      "\n",
      "       [[492, 295]],\n",
      "\n",
      "       [[492, 160]],\n",
      "\n",
      "       [[493, 159]],\n",
      "\n",
      "       [[492, 158]],\n",
      "\n",
      "       [[487, 158]],\n",
      "\n",
      "       [[486, 157]]], dtype=int32), array([[[101, 119]],\n",
      "\n",
      "       [[102, 118]],\n",
      "\n",
      "       [[265, 118]],\n",
      "\n",
      "       [[266, 119]],\n",
      "\n",
      "       [[267, 119]],\n",
      "\n",
      "       [[268, 120]],\n",
      "\n",
      "       [[268, 223]],\n",
      "\n",
      "       [[269, 224]],\n",
      "\n",
      "       [[268, 225]],\n",
      "\n",
      "       [[268, 226]],\n",
      "\n",
      "       [[267, 227]],\n",
      "\n",
      "       [[266, 227]],\n",
      "\n",
      "       [[265, 228]],\n",
      "\n",
      "       [[264, 227]],\n",
      "\n",
      "       [[103, 227]],\n",
      "\n",
      "       [[102, 228]],\n",
      "\n",
      "       [[101, 227]],\n",
      "\n",
      "       [[ 99, 227]],\n",
      "\n",
      "       [[ 98, 226]],\n",
      "\n",
      "       [[ 98, 120]],\n",
      "\n",
      "       [[ 99, 119]]], dtype=int32), array([[[102, 118]],\n",
      "\n",
      "       [[101, 119]],\n",
      "\n",
      "       [[ 99, 119]],\n",
      "\n",
      "       [[ 98, 120]],\n",
      "\n",
      "       [[ 98, 226]],\n",
      "\n",
      "       [[ 99, 227]],\n",
      "\n",
      "       [[101, 227]],\n",
      "\n",
      "       [[102, 228]],\n",
      "\n",
      "       [[103, 227]],\n",
      "\n",
      "       [[264, 227]],\n",
      "\n",
      "       [[265, 228]],\n",
      "\n",
      "       [[266, 227]],\n",
      "\n",
      "       [[268, 227]],\n",
      "\n",
      "       [[268, 225]],\n",
      "\n",
      "       [[269, 224]],\n",
      "\n",
      "       [[268, 223]],\n",
      "\n",
      "       [[268, 119]],\n",
      "\n",
      "       [[266, 119]],\n",
      "\n",
      "       [[265, 118]]], dtype=int32), array([[[520,  63]],\n",
      "\n",
      "       [[781,  63]],\n",
      "\n",
      "       [[782,  64]],\n",
      "\n",
      "       [[782, 310]],\n",
      "\n",
      "       [[781, 311]],\n",
      "\n",
      "       [[519, 311]],\n",
      "\n",
      "       [[518, 310]],\n",
      "\n",
      "       [[518,  65]]], dtype=int32), array([[[520,  63]],\n",
      "\n",
      "       [[518,  65]],\n",
      "\n",
      "       [[518, 310]],\n",
      "\n",
      "       [[519, 311]],\n",
      "\n",
      "       [[782, 311]],\n",
      "\n",
      "       [[782,  64]],\n",
      "\n",
      "       [[781,  63]]], dtype=int32), array([[[ 15,  20]],\n",
      "\n",
      "       [[ 16,  19]],\n",
      "\n",
      "       [[326,  19]],\n",
      "\n",
      "       [[327,  20]],\n",
      "\n",
      "       [[328,  19]],\n",
      "\n",
      "       [[329,  20]],\n",
      "\n",
      "       [[330,  20]],\n",
      "\n",
      "       [[331,  21]],\n",
      "\n",
      "       [[330,  22]],\n",
      "\n",
      "       [[330, 303]],\n",
      "\n",
      "       [[331, 304]],\n",
      "\n",
      "       [[331, 306]],\n",
      "\n",
      "       [[329, 308]],\n",
      "\n",
      "       [[328, 308]],\n",
      "\n",
      "       [[327, 309]],\n",
      "\n",
      "       [[326, 308]],\n",
      "\n",
      "       [[ 16, 308]],\n",
      "\n",
      "       [[ 15, 307]],\n",
      "\n",
      "       [[ 15, 306]],\n",
      "\n",
      "       [[ 14, 305]],\n",
      "\n",
      "       [[ 14,  23]],\n",
      "\n",
      "       [[ 15,  22]]], dtype=int32), array([[[ 16,  19]],\n",
      "\n",
      "       [[ 15,  20]],\n",
      "\n",
      "       [[ 15,  22]],\n",
      "\n",
      "       [[ 14,  23]],\n",
      "\n",
      "       [[ 14, 305]],\n",
      "\n",
      "       [[ 15, 306]],\n",
      "\n",
      "       [[ 15, 308]],\n",
      "\n",
      "       [[326, 308]],\n",
      "\n",
      "       [[327, 309]],\n",
      "\n",
      "       [[328, 308]],\n",
      "\n",
      "       [[330, 308]],\n",
      "\n",
      "       [[330, 307]],\n",
      "\n",
      "       [[331, 306]],\n",
      "\n",
      "       [[331, 304]],\n",
      "\n",
      "       [[330, 303]],\n",
      "\n",
      "       [[330,  22]],\n",
      "\n",
      "       [[331,  21]],\n",
      "\n",
      "       [[330,  20]],\n",
      "\n",
      "       [[329,  20]],\n",
      "\n",
      "       [[328,  19]],\n",
      "\n",
      "       [[327,  20]],\n",
      "\n",
      "       [[326,  19]]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\shapes_donut.jpg')\n",
    "cv2.imshow('Input Images',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#grayscaling\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#find canny edges\n",
    "edged=cv2.Canny(gray,30,200)\n",
    "cv2.imshow('Canny Edges',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#finding contors\n",
    "#use a copy of image coz find contors alters the image(func used-->edged.copy())\n",
    "contors,hierarchy=cv2.findContours(edged,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('canny edges after contoring',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"no. of contors found=\",len(contors))\n",
    "print(contors)\n",
    "#draw all contors\n",
    "#use -1 as the 3rd parameter to draw all\n",
    "cv2.drawContours(image,contors,-1,(0,255,0),3)   #num parameters are--num of contors(-1 for all),colour,thickness\n",
    "\n",
    "cv2.imshow('Contors',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img=cv2.imread('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yaha se vo 3 hrs vali video aati hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\walking.avi')\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    cv2.imshow('video',img)       \n",
    "    if cv2.waitKey(1000) & 0xFF==ord('q'):                                #more wait slower the video plays\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,640)           #width feature\n",
    "cap.set(4,480)           #height feature\n",
    "cap.set(10,-1)         #for brightness\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    cv2.imshow('video',img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('g'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\Trump.jpg')\n",
    "cv2.imshow('Trump',img)\n",
    "cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "\n",
    "imgGray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur=cv2.GaussianBlur(imgGray,(7,7),0)\n",
    "imgCanny=cv2.Canny(imgGray,100,100)                    #edgedetector 100,100 is threshold\n",
    "imgDilation=cv2.dilate(imgCanny,kernel,iterations=1)\n",
    "imgEroded=cv2.erode(imgDilation,kernel,iterations=1)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Gray TRUMP',imgGray)\n",
    "cv2.imshow('BlurGRAY trump',imgBlur)\n",
    "cv2.imshow('Edgy Trump',imgCanny)\n",
    "cv2.imshow('Dilated Trump',imgDilation)\n",
    "cv2.imshow('Eroded Trump',imgEroded)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 32-33: truncated \\UXXXXXXXX escape (<ipython-input-8-947aed725869>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-947aed725869>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    cv2.waitKey(1000)\"\"\"\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 32-33: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"import cv2\n",
    "img=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\Trump.jpg')\n",
    "for x in range(20):\n",
    "    for y in range(20):\n",
    "        canned=cv2.Canny(img,10*x,10*y)\n",
    "        cv2.waitKey(1000)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465, 342, 3)\n",
      "(100, 100, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img=cv2.imread(r'C:\\Users\\kapri\\Desktop\\Master OpenCV\\images\\Trump.jpg')\n",
    "print(img.shape)\n",
    "\n",
    "imgResize=cv2.resize(img,(100,100))\n",
    "print(imgResize.shape)\n",
    "cv2.imshow(\"orig\",img)\n",
    "cv2.imshow('resized',imgResize)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:/projects/opencv-python/opencv/modules/highgui/src/precomp.hpp:137: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1c90e8784645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m666\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m666\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ar'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:/projects/opencv-python/opencv/modules/highgui/src/precomp.hpp:137: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ar=np.random.randint(100,size=(666,666,3))\n",
    "cv2.imshow('ar',ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "BLACK=[0,0,0]\n",
    "im=cv2.imread(r'C:\\Users\\kapri\\Pictures\\s.png')\n",
    "cv2.imshow('aa',im)\n",
    "expanded_image = cv2.copyMakeBorder(im,0,0,375,0,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "cv2.putText(expanded_image, \"test-sample\", (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,4, (0,0,255), 4)\n",
    "\n",
    "cv2.imshow('expanded',expanded_image)\n",
    "cv2.waitKey(0)=='13'\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image=np.random.randint(0,255,size=(720,720,3),dtype='uint8')\n",
    "\n",
    "cv2.imshow('random',image)\n",
    "cv2.waitKey(0)=='13'\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.cvtColor(image,cv2.COL)\n",
    "canny=cv2.canny(gray,20,80)\n",
    "cv2.imshow('canny',canny)\n",
    "cv2.waitKey(0)=='13'\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a32398aaaac2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m tf.test.is_gpu_available(\n\u001b[0;32m      3\u001b[0m     \u001b[0mcuda_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_cuda_compute_capability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
